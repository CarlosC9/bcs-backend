import json
import logging
import os
import re
import shutil
import signal
import stat
import subprocess
import traceback
from functools import partial
from json import JSONDecodeError

from dotted.collection import DottedDict

from .. import get_global_configuration_variable
from ..common import ROOT
from ..common.decorators import celery_wf
from ..jobs import JobExecutorAtResourceFactory
from ..rest import app_api_base, logger
from . import celery_app

"""
To debug Celery tasks, create a Run/Debug configuration:
 * of type "Python"
 * Script path: /home/rnebot/anaconda3/bin/celery
 * Parameters-: -A rvc.tasks worker --pool=solo --loglevel=info
 * Python interpreter: <use the same environment where the Backend is executed
 * Optionally, create a Run/Debug configuration of type "Compound":
   - Add the previous Run/Debug configuration
   - Also, the Run/Debug configuration for the Backend 

To test:
- Run "app-backend" in the IDE
- Open three shells in the "app-backend" directory:
  - ./start_local_dev_services.sh
  - python3 biobarcoding/rest/main.py
  - celery -A biobarcoding.tasks.definitions flower [OPTIONAL: to see tasks, http://localhost:5555]
  - curl -i -XPOST http://localhost:5000/api/jobs/ --data-urlencode "{}" --> (should return immediately)
    - (to see messages generated by tasks of this workflow) tail -f /home/rnebot/Downloads/borrame/log.txt
  - curl -i -XPOST http://localhost:5000/api/jobs/ -H "Content-Type: application/json" -d @"/home/daniel/Documentos/GIT/app-backend/tests/request_transfer.json"
  - curl --cookie-jar app-cookies.txt --cookie app-cookies.txt -XPOST http://localhost:5000/api/jobs/ -H "Content-Type: application/json" -d @"/home/paula/Documentos/app-backend/tests/data_test/new_galaxy_request.json"

"""

MAX_ATTEMPTS = 3
CELERY_LOG = ROOT + "/tests/data_test/celery_log.txt"
wf1 = {
    "prepare": {
        "": "export",
        "error": "error",
        "cancel": "cleanup"
    },
    "export": {
        "": "transfer_data",
        "cancel": "cleanup"
    },
    "transfer_data": {
        "": "submit",
        "cancel": "cleanup"
    },
    "submit": {
        "cancel": "cleanup",
        "": "wait_until_execution_starts"
    },
    "wait_until_execution_starts": {
        "": "wait_for_execution_end",
        "error": "error",
        "cancel": "cleanup"
    },
    "wait_for_execution_end": {
        "": "transfer_data_from",
        "error": "error",
        "cancel": "cleanup"
    },
    "transfer_data_from": {
        "": "store_result_in_backend",
        "cancel": "cancel"
    },
    "store_result_in_backend": {
        "": "cleanup",
        "cancel": "cancel"
    },
    "cleanup": {
        "": "success",
        "cancel": "cancel"
    },
    # "success"
    # "error"
    # "cancelled"
}


def put_json_at_backend_endpoint(path: str, json_str: str):
    endpoint = get_global_configuration_variable("ENDPOINT_URL")
    cookies_file_path = get_global_configuration_variable("COOKIES_FILE_PATH")
    url = f"{endpoint}{app_api_base}{path}"
    api_login()
    cmd = ["curl", "--cookie-jar", cookies_file_path, "--cookie", cookies_file_path, "-H",
           "Content-Type: application/json", "-XPUT", "--data-binary", json_str, url]
    proc = subprocess.run(cmd, capture_output=True, text=True)
    try:
        process_return_dict = json.loads(proc.stdout)
        return process_return_dict.get("content", {})
    except JSONDecodeError:
        traceback.print_exc()
        return {}


def refresh_status(d: DottedDict, status: str):
    job_id = d.job_id
    url = f"/jobs/{job_id}"
    status_request = json.dumps(dict(status=status))
    output = put_json_at_backend_endpoint(url, status_request)
    status_set = output.get("status", status)
    d.status = status_set
    return status_set


def change_status_or_cancel_if_requested(jc, job_status, cancel_task_function):
    """
    First it tries to change the "status" property of the Job (used to inform progress)

    If the status returned by the Backend is "cancelling", it returns False
    True is returned otherwise

    When cancelling:
     * call the "cancel_task_function" (if defined)
     * return False to inform tasks that they must cancel its current process and move to "cleanup"

    :param jc:
    :param job_status:
    :param cancel_task_function:
    :return:
    """
    status = refresh_status(jc, job_status)
    if status == "cancelling":
        if cancel_task_function:
            cancel_task_function()
        return False
    else:
        return True


def kill_process(pid):
    if pid:
        try:
            os.kill(int(pid), signal.SIGTERM)
        except Exception as e:
            print(e)
            traceback.print_exc()


def call_app_entity_status_callback(jc: DottedDict, status: str):
    """
    "app entity" considered to be a separate thing from elaboration (job execution) of it
    Useful to provide higher level view of the status of this entity (without knowing about "jobs")

    :param jc:
    :param status:
    :return:
    """
    s = f"{status}_status"
    if "callbacks" in jc.process and "endpoint" in jc.process.callbacks and s in jc.process.callbacks:
        status_request = json.dumps(dict(status=status))
        output = put_json_at_backend_endpoint(jc.process.callbacks.endpoint, status_request)
        if output:
            status_set = output.get("status", status)


def can_execute_job(job_id):
    endpoint = get_global_configuration_variable("ENDPOINT_URL")
    cookies_file_path = get_global_configuration_variable("COOKIES_FILE_PATH")
    url = f"{endpoint}{app_api_base}/jobs/{job_id}"
    api_login()
    cmd = ["curl", "--cookie", cookies_file_path, f"{url}"]
    proc = subprocess.run(cmd, capture_output=True, text=True)
    _ = proc.stdout
    api_logout()
    try:
        d = json.loads(_)
    except JSONDecodeError as e:
        print(e)
        return False
    if d.get("content"):
        _ = d["content"]
        executability = _.get("executability",
                              "resource_ok_can_execute" if _["status"] in ("cancelled", "cancelling") else "resource_ko")
        return executability == "resource_ok_can_execute"
    else:
        if d.get("issues"):
            if d["issues"][0]["type"] == "ERROR" and "not found" in d["issues"][0]["message"]:
                return "job_does_not_exist"  # Not a boolean
        return False


def write_to_file(filename, s):
    try:
        with open(filename, "a+") as f:
            f.write(s + "\r\n")
    except:
        logger.debug(f"Warning: could not write '{s}' to file '{filename}'")


celery_user = "celery_user"


def api_login():
    endpoint = get_global_configuration_variable("ENDPOINT_URL")
    cookies_file_path = get_global_configuration_variable("COOKIES_FILE_PATH")
    url = f"{endpoint}{app_api_base}/authn?user={celery_user}"
    cmd = ["curl", "--cookie", cookies_file_path, "--cookie-jar", cookies_file_path, "-X", "PUT", url]
    subprocess.run(cmd)


def api_logout():
    endpoint = get_global_configuration_variable("ENDPOINT_URL")
    # cookies_file_path = get_global_configuration_variable("COOKIES_FILE_PATH")
    # url = f"{endpoint}{app_api_base}/authn?user={celery_user}"
    # cmd = ["curl", "--cookie", cookies_file_path, "--cookie-jar", cookies_file_path, "-X", "DELETE", url]
    # subprocess.run(cmd)


def check_file_is_stored_in_backend(check_url):
    if not check_url:
        return False
    cookies_file_path = get_global_configuration_variable("COOKIES_FILE_PATH")
    api_login()
    cmd = ["curl", "--cookie-jar", cookies_file_path, "--cookie",
           cookies_file_path, f"{check_url}"]
    proc = subprocess.run(cmd, capture_output=True, text=True)
    _ = proc.stdout
    api_logout()
    try:
        process_return_dict = json.loads(_)
    except JSONDecodeError as e:
        print(e)
        return False
    if process_return_dict.get("content"):
        return process_return_dict["content"].get("size") != 0
    else:
        return False


def clean_failed_results(result_files, local_workspace):
    clean_results = []
    for f in result_files:
        if os.path.exists(os.path.join(local_workspace, f["file"])):
            clean_results.append(f)
    return clean_results


def remove_local_workspace(local_workspace, result_files=None):
    print("remove_local_workspace")
    shutil.rmtree(local_workspace)
    if os.path.exists(local_workspace):
        os.rmdir(local_workspace)
        print("rmdir")
    if os.path.exists(local_workspace) and os.path.isdir(local_workspace):
        print("why????")
    if os.path.exists(local_workspace):
        print("?????")

    # result_filenames = [os.path.basename(f["file"]) for f in result_files]
    # for f in os.listdir(local_workspace):
    #     if f not in result_filenames:
    #         os._(os.path.join(local_workspace, f))


def local_workspace_exists(local_workspace, result_files=None):
    return os.path.exists(local_workspace)
    # cleaned = True
    # result_filenames = [os.path.basename(f["file"]) for f in result_files]
    # local_workspace_files = os.listdir(local_workspace)
    # if len(result_filenames) == len(local_workspace_files):
    #     for f in local_workspace_files:
    #         if f not in result_filenames:
    #             cleaned = False
    # else:
    #     cleaned = False
    # return cleaned


def write_to_universal_log_and_truncate(step_stdout, step_stderr, universal_log):
    stdout_file = open(step_stdout, 'r+')
    stderr_file = open(step_stderr, 'r+')
    stdout = stdout_file.read()
    stderr = stderr_file.read()
    stdout_file.truncate(0)
    stderr_file.truncate(0)
    stdout_file.close()
    stderr_file.close()

    step_log = f"\n{stdout}\nAPP_STDERR\n{stderr}APP_STDERR\n"
    with open(universal_log, "a+") as universal_log_file:
        universal_log_file.write(step_log)


def generate_export_cmd(file_dict: dict, tmp_path: str, job_executor):
    endpoint: str = get_global_configuration_variable("ENDPOINT_URL")
    cookies_file_path: str = get_global_configuration_variable("COOKIES_FILE_PATH")
    extension: str = file_dict['type']
    object_type: dict = file_dict['object_type']
    selection = file_dict['selection']
    with_filter = False
    if type(selection) == dict:  # Get with filter
        selection_json: str = json.dumps(selection)
        with_filter = True
    url = ""
    if "bos" in object_type.keys():
        url = f"{endpoint}{app_api_base}/bos/{object_type['bos']}.{extension}"
    elif "geo" in object_type.keys():
        if object_type['geo'] == "layers":
            url = f"{endpoint}{app_api_base}/geo/{object_type['geo']}/{selection}.{extension}"
    elif "files" in object_type.keys():
        url = f"{endpoint}{app_api_base}/files/{object_type['files']}.content"

    if with_filter:
        curl = (f"curl --cookie-jar {cookies_file_path} --cookie {cookies_file_path} -X GET -d \'{selection_json}\' " +
                f"-H \'Content-Type:application/json\' {url} -o \'{tmp_path}\'")
        return (f"(nohup bash -c &quot;{curl}&quot; >>{job_executor.log_filenames_dict['export_stdout']} " +
                f"</dev/null 2>>{job_executor.log_filenames_dict['export_stderr']} & echo $!; wait $!; " +
                f"echo $? >> {job_executor.local_workspace}/$!.exit_status)")
    else:
        curl = f"curl --cookie {cookies_file_path} -X GET {url} -o \'{tmp_path}\'"
        return (f"(nohup bash -c \"{curl}\" >>{job_executor.log_filenames_dict['export_stdout']} " +
                f"</dev/null 2>>{job_executor.log_filenames_dict['export_stderr']} & echo $!; wait $!; " +
                f"echo $? >> {job_executor.local_workspace}/$!.exit_status)")


# TODO: Hay que prepararlo para las colecciones y los ficheros que suba el usuario de manera
#  que se puedan concatenar si se refieren al mismo fichero.
#  Mirar: https://stackoverflow.com/questions/40359012/how-to-append-a-file-with-the-existing-one-using-curl

def export(file_dict, job_executor) -> object:
    """
    Export file to the local workspace (which depends on "job_executor")

    @param file_dict: Dictionary of the file to be exported
    @param job_executor: Needed to know local_workspace and log names
    @return: pid: PID of the executed script process
    """
    api_login()  # Logout is executed after successful export
    tmp_path = os.path.join(job_executor.local_workspace, file_dict["remote_name"])
    cmd = generate_export_cmd(file_dict, tmp_path, job_executor)
    print(cmd)
    popen_pipe = os.popen(cmd)
    pid = popen_pipe.readline().rstrip()
    print(f"PID: {pid}")
    return pid


def is_file_exported(input_file):
    if os.path.exists(input_file):  # and check that it is not an error file:
        try:
            with open(input_file, "r") as file:
                file_content = file.read()
                file.close()
            if not re.search(r'\b<!DOCTYPE HTML PUBLIC\b', file_content):
                return True
            else:
                print(f"{input_file} is a html file")
                return False
        except:
            return True  # If the search cannot be performed, it is a binary file, OK
    else:
        print(f"{input_file} does not exists")
        return False


def s2d(s: str) -> DottedDict:
    return DottedDict(json.loads(s))


def d2s(d: DottedDict) -> str:
    return json.dumps(d.to_python())


@celery_app.task(name="prepare")
@celery_wf(celery_app, wf1, "prepare")
def wf1_prepare_workspace(job_context):
    """
    Prepare workspace for execution of a Job
    :param job_context:
    :return:
    """
    jc = s2d(job_context)

    # Before proceeding with this and next tasks, check if execution must be contained,
    # wait 5 seconds if that is the case and return here
    if jc.status == "created":
        res = can_execute_job(jc.job_id)
        if res == "job_does_not_exist":
            return "error", d2s(jc)
        elif not res:
            return 5, job_context

    job_executor = JobExecutorAtResourceFactory().get(jc)
    if not change_status_or_cancel_if_requested(jc, "preparing_workspace", None):
        return "cancel", job_context

    state = jc.get("state_dict")

    logging.debug(f"Prepare state: {state}")

    if state:  # ya ha empezado el prepare
        n_attempts = state.n_attempts
    else:
        n_attempts = 0
        write_to_file(job_executor.log_filenames_dict["prepare_stdout"],
                      "#" * 25 + " PREPARE WORKSPACE STEP " + "#" * 25)
        # TODO Why this open? Exclusive creation but then it is not closed
        open(job_executor.log_filenames_dict["prepare_stderr"], "x")
        jc.state_dict = dict(n_attempts=n_attempts, state="prepare")

    if not job_executor.check():  # No connection to the compute resource
        error_str = "Connection to the server has been lost"
        jc.error = error_str
        write_to_file(job_executor.log_filenames_dict["prepare_stderr"], error_str)
        write_to_universal_log_and_truncate(job_executor.log_filenames_dict["prepare_stdout"],
                                            job_executor.log_filenames_dict["prepare_stderr"],
                                            job_executor.log_filenames_dict["universal_log"])
        return "error", d2s(jc)
    elif n_attempts >= MAX_ATTEMPTS:  # Maximum number of
        jc.error = f"It was impossible to prepare the working directory of Job {jc.job_id}." + \
                   f"Maybe it could be due to some disk space or credentials issue."
        write_to_file(job_executor.log_filenames_dict["prepare_stderr"], jc.error)
        write_to_universal_log_and_truncate(job_executor.log_filenames_dict["prepare_stdout"],
                                            job_executor.log_filenames_dict["prepare_stderr"],
                                            job_executor.log_filenames_dict["universal_log"])
        return "error", d2s(jc)
    elif job_executor.job_workspace_exists() or job_executor.job_workspace_exists() is None:
        print("job workspace created")
        # None when the job is executed in localhost
        write_to_file(job_executor.log_filenames_dict["prepare_stdout"], f"Job {jc.job_id} workspace prepared")
        write_to_universal_log_and_truncate(job_executor.log_filenames_dict["prepare_stdout"],
                                            job_executor.log_filenames_dict["prepare_stderr"],
                                            job_executor.log_filenames_dict["universal_log"])
        del jc.state_dict
        return d2s(jc)
    else:
        write_to_file(job_executor.log_filenames_dict["prepare_stdout"],
                      f"Preparing Job {jc.job_id} workspace: Attempt: {n_attempts + 1}")
        jc.state_dict = dict(n_attempts=n_attempts + 1, state="prepare")
        # NOTE: Local workspace is created implicitly by "JobExecutorAtResourceFactory().get(jc)"
        job_executor.create_job_workspace()
        return None, d2s(jc)


@celery_app.task(name="export")
@celery_wf(celery_app, wf1, "export")
def wf1_export_to_supported_file_formats(job_context: str):
    """
    Prepare input files by exporting data using RESTful services

    :param job_context:
    :return:
    """
    jc = s2d(job_context)
    job_executor = JobExecutorAtResourceFactory().get(jc)

    if not change_status_or_cancel_if_requested(jc,
                                                "export",
                                                partial(kill_process, jc.get("pid"))):
        return "cancel", job_context

    state = jc.get("state_dict")

    print(f"Export state: {state}")

    if state:  # ya ha empezado la transferencia
        i = state.idx
        n_attempts = state.n_attempts
    else:
        write_to_file(job_executor.log_filenames_dict["export_stdout"],
                      "#" * 20 + " EXPORT TO SUPPORTED FILE FORMATS STEP " + "#" * 20)
        open(job_executor.log_filenames_dict["export_stderr"], "x")
        i = 0
        n_attempts = 0
        jc.pid = None
        jc.state_dict = dict(idx=i, n_attempts=n_attempts, state="export")

    # Files to export
    files = jc.process.inputs.data
    file_dict = files[i] if i < len(files) else dict(file="", remote_name="", type="")
    print(file_dict)

    if i < len(files) and n_attempts >= MAX_ATTEMPTS:
        error_str = f"Export error: File {i + 1} {file_dict['remote_name']}"
        write_to_file(job_executor.log_filenames_dict["export_stderr"], error_str)
        write_to_universal_log_and_truncate(job_executor.log_filenames_dict["export_stdout"],
                                            job_executor.log_filenames_dict["export_stderr"],
                                            job_executor.log_filenames_dict["universal_log"])
        jc.error = error_str
        return "error", d2s(jc)
    if i == len(files):  # Export finished
        print("Export finished")
        write_to_file(job_executor.log_filenames_dict["export_stdout"], "Export finished successfully")
        write_to_universal_log_and_truncate(job_executor.log_filenames_dict["export_stdout"],
                                            job_executor.log_filenames_dict["export_stderr"],
                                            job_executor.log_filenames_dict["universal_log"])
        del jc.state_dict
        return d2s(jc)
    elif job_executor.step_status(jc) == "running":  # Export is being executed
        print("Export executing")
        return 1, job_context
    elif job_executor.step_status(jc) == "":
        jc.pid = None
        return None, d2s(jc)
    elif is_file_exported(os.path.join(job_executor.local_workspace, file_dict["remote_name"])):
        print(f"File {file_dict['remote_name']} transferred -> Moving to next")
        write_to_file(job_executor.log_filenames_dict["export_stdout"],
                      f"File {file_dict['remote_name']} exported -> Moving to next")
        write_to_universal_log_and_truncate(job_executor.log_filenames_dict["export_stdout"],
                                            job_executor.log_filenames_dict["export_stderr"],
                                            job_executor.log_filenames_dict["universal_log"])
        jc.process.inputs.data[i]['file'] = os.path.join(job_executor.local_workspace, file_dict["remote_name"])
        del jc.process.inputs.data[i]['selection']
        jc.pid = None
        jc.state_dict = dict(idx=i + 1, n_attempts=0, state="export")
        api_logout()
        return None, d2s(jc)
    else:  # Export file i
        print(f"Begin export {i + 1}: {file_dict['remote_name']}. Attempt: {n_attempts + 1}")
        write_to_file(job_executor.log_filenames_dict["export_stdout"],
                      f"Begin export {i + 1}: {file_dict['remote_name']}. Attempt: {n_attempts + 1}")
        write_to_universal_log_and_truncate(job_executor.log_filenames_dict["export_stdout"],
                                            job_executor.log_filenames_dict["export_stderr"],
                                            job_executor.log_filenames_dict["universal_log"])
        pid = export(file_dict, job_executor)  # MAIN!!!
        jc.pid = pid
        jc.state_dict = dict(idx=i, n_attempts=n_attempts + 1, state="export")
        return None, d2s(jc)


@celery_app.task(name="transfer_data")
@celery_wf(celery_app, wf1, "transfer_data")
def wf1_transfer_data_to_resource(job_context: str) -> object:
    """
    Transfer data to the compute resource
    :param job_context:
    :return:
    """
    jc = s2d(job_context)
    job_executor = JobExecutorAtResourceFactory().get(jc)

    if not change_status_or_cancel_if_requested(jc,
                                                "transfer_data_to_resource",
                                                partial(kill_process, jc.get("pid"))):
        return "cancel", job_context

    state = jc.get("state_dict")
    print(f"Transfer state: {state}")
    if state:  # ya ha empezado la transferencia
        i = state.idx
        n_attempts = state.n_attempts
    else:
        write_to_file(job_executor.log_filenames_dict["upload_stdout"],
                      "#" * 20 + " TRANSFER DATA TO SOURCE STEP " + "#" * 20)
        open(job_executor.log_filenames_dict["upload_stderr"], "x")
        i = 0
        n_attempts = 0
        jc.pid = None
        jc.state_dict = dict(idx=i, n_attempts=n_attempts, state="upload")

    # Files to transfer
    files = job_executor.get_upload_files_list(jc)
    file_dict = files[i] if i < len(files) else {"file": "", "remote_name": "", "type": ""}

    if not job_executor.check():
        error_str = "Connection to the server has been lost"
        print(error_str)
        write_to_file(job_executor.log_filenames_dict["upload_stderr"], error_str)
        write_to_universal_log_and_truncate(job_executor.log_filenames_dict["upload_stdout"],
                                            job_executor.log_filenames_dict["upload_stderr"],
                                            job_executor.log_filenames_dict["universal_log"])
        jc.error = error_str
        return "error", d2s(jc)
    elif i < len(files) and n_attempts >= MAX_ATTEMPTS:
        error_str = f"Transfer of file {os.path.basename(file_dict['file'])} to resource failed."
        write_to_file(job_executor.log_filenames_dict["upload_stderr"], error_str)
        write_to_universal_log_and_truncate(job_executor.log_filenames_dict["upload_stdout"],
                                            job_executor.log_filenames_dict["upload_stderr"],
                                            job_executor.log_filenames_dict["universal_log"])
        print(error_str)
        jc.error = error_str
        return "error", d2s(jc)
    elif i == len(files):  # Transfer finished
        print("Transfer finished")
        write_to_file(job_executor.log_filenames_dict["upload_stdout"],
                      "Upload finished successfully")
        write_to_universal_log_and_truncate(job_executor.log_filenames_dict["upload_stdout"],
                                            job_executor.log_filenames_dict["upload_stderr"],
                                            job_executor.log_filenames_dict["universal_log"])
        del jc.state_dict
        return d2s(jc)
    elif job_executor.step_status(jc) == "running":  # Transfer is being executed
        print("Transfer executing")
        return 1, job_context
    elif job_executor.step_status(jc) == "":  # Transfer error
        print(f"Transfer error: File {i + 1}")
        jc.pid = None
        return None, d2s(jc)
    elif job_executor.exists(jc):  # File i has been transferred successfully
        print(f"File {file_dict['file']} transferred -> Moving to next. Attempt: {n_attempts}")
        write_to_file(job_executor.log_filenames_dict["upload_stdout"],
                      (f"File {os.path.basename(file_dict['file'])} transferred -> "
                       f"Moving to next. Attempt: {n_attempts + 1}"))
        write_to_universal_log_and_truncate(job_executor.log_filenames_dict["upload_stdout"],
                                            job_executor.log_filenames_dict["upload_stderr"],
                                            job_executor.log_filenames_dict["universal_log"])
        i += 1
        jc.pid = None
        jc.state_dict = dict(idx=i, n_attempts=0, state="upload")
        return None, d2s(jc)
    else:  # Transfer file i
        print(f"Begin transfer {i + 1}: {file_dict['file']}")
        write_to_file(job_executor.log_filenames_dict["upload_stdout"],
                      f"Begin transfer {i + 1}: {file_dict['file']}")
        pid = job_executor.upload_file(jc)  # MAIN !!!
        jc.pid = pid
        jc.state_dict = dict(idx=i, n_attempts=n_attempts + 1, state="upload")
        print(jc.state_dict)
        return None, d2s(jc)


@celery_app.task(name="submit")
@celery_wf(celery_app, wf1, "submit")
def wf1_submit(job_context: str):
    """
    Submit job to compute resource
    :param job_context:
    :return:
    """
    jc = s2d(job_context)
    job_executor = JobExecutorAtResourceFactory().get(jc)

    if not change_status_or_cancel_if_requested(jc,
                                                "submit",
                                                partial(job_executor.cancel_job, jc.get("pid"))):
        return "cancel", job_context

    write_to_file(job_executor.log_filenames_dict["submit_stdout"], "#" * 25 + " SUBMIT STEP " + "#" * 25)
    open(job_executor.log_filenames_dict["submit_stderr"], "x")

    jc.pid = job_executor.submit(jc["process"])  # MAIN !!!

    jc.state_dict = dict(state="submit", substep="submit")
    write_to_file(CELERY_LOG, f"Submit job with PID: {jc.pid}")
    write_to_file(job_executor.log_filenames_dict["submit_stdout"],
                  f"Submit job with PID: {jc.pid}")
    return d2s(jc)


@celery_app.task(name="wait_until_execution_starts")
@celery_wf(celery_app, wf1, "wait_until_execution_starts")
def wf1_wait_until_execution_starts(job_context: str):
    """
    Wait for the job to start executing at the
    :param job_context:
    :return:
    """
    jc = s2d(job_context)
    job_executor = JobExecutorAtResourceFactory().get(jc)

    if not change_status_or_cancel_if_requested(jc,
                                                "wait_until_execution_starts",
                                                partial(job_executor.cancel_job, jc.get("pid"))):
        return "cancel", job_context

    jc.state_dict = dict(state="submit", substep="wait_until_execution_starts")
    if not job_executor.check():
        error_str = "Connection to the server has been lost"
        write_to_file(job_executor.log_filenames_dict["submit_stderr"], error_str)
        write_to_universal_log_and_truncate(job_executor.log_filenames_dict["submit_stdout"],
                                            job_executor.log_filenames_dict["submit_stderr"],
                                            job_executor.log_filenames_dict["universal_log"])
        print(error_str)
        jc.error = error_str
        return "error", d2s(jc)
    status = job_executor.step_status(jc)
    write_to_file(CELERY_LOG, f"wait_until_execution_starts: status: {status}")
    # TODO: el step_status debería de sacar outputs uniformes. Se podría escribir ese
    # status en el log en el job_executor?
    if isinstance(status, dict) or status == "":
        if status != "":
            jc.process.error = status
            error_str = f"The process failed to start with status: {status}."
        else:
            error_str = "The process failed to start."
        print(error_str)
        write_to_file(job_executor.log_filenames_dict["submit_stderr"], json.dumps(error_str))
        write_to_universal_log_and_truncate(job_executor.log_filenames_dict["submit_stdout"],
                                            job_executor.log_filenames_dict["submit_stderr"],
                                            job_executor.log_filenames_dict["universal_log"])
        jc.error = error_str
        return 'error', d2s(jc)
    elif status == 'running' or status == 'ok':
        return job_context
    else:
        return 3, job_context


@celery_app.task(name="wait_for_execution_end")
@celery_wf(celery_app, wf1, "wait_for_execution_end")
def wf1_wait_for_execution_end(job_context: str):
    """
    Wait for the job to finish execution, knowing it is running
    When finished, it can end successfully or with an error.

    :param job_context:
    :return:
    """
    jc = s2d(job_context)
    job_executor = JobExecutorAtResourceFactory().get(jc)

    if not change_status_or_cancel_if_requested(jc,
                                                "wait_for_execution_end",
                                                partial(job_executor.cancel_job, jc.get("pid"))):
        return "cancel", job_context

    jc.state_dict = dict(state="submit", substep="wait_for_execution_end")
    status = job_executor.step_status(jc)
    write_to_file(CELERY_LOG, f"wait_for_execution_end: status: {status}")
    if not job_executor.check():
        error_str = "Connection to the server has been lost"
        print(error_str)
        write_to_file(job_executor.log_filenames_dict["submit_stderr"], error_str)
        write_to_universal_log_and_truncate(job_executor.log_filenames_dict["submit_stdout"],
                                            job_executor.log_filenames_dict["submit_stderr"],
                                            job_executor.log_filenames_dict["universal_log"])
        jc.error = error_str
        return "error", d2s(jc)
    elif isinstance(status, dict):
        jc.process.error = status
        write_to_file(job_executor.log_filenames_dict["submit_stderr"], json.dumps(status))
        return 'error', d2s(jc)
    elif status == 'ok':
        del jc.state_dict
        write_to_file(job_executor.log_filenames_dict["submit_stdout"],
                      "Job execution finished successfully.")
        write_to_universal_log_and_truncate(job_executor.log_filenames_dict["submit_stdout"],
                                            job_executor.log_filenames_dict["submit_stderr"],
                                            job_executor.log_filenames_dict["universal_log"])
        return d2s(jc)
    elif status == "":
        # TODO job_executor.write_submit_logs()
        write_to_file(job_executor.log_filenames_dict["submit_stdout"],
                      "Job execution finished in error.")
        write_to_universal_log_and_truncate(job_executor.log_filenames_dict["submit_stdout"],
                                            job_executor.log_filenames_dict["submit_stderr"],
                                            job_executor.log_filenames_dict["universal_log"])
        return 'error', job_context
    else:
        return 3, job_context


@celery_app.task(name="transfer_data_from")
@celery_wf(celery_app, wf1, "transfer_data_from")
def wf1_transfer_data_from_resource(job_context: str):
    """
    Once the computation ends, transfer results from the resource to local
    :param job_context:
    :return:
    """
    jc = s2d(job_context)

    job_executor = JobExecutorAtResourceFactory().get(jc)
    if not change_status_or_cancel_if_requested(jc,
                                                "transfer_data_from_resource",
                                                partial(kill_process, jc.get("pid"))):
        return "cancel", job_context

    state = jc.get("state_dict")
    print(f"Transfer state: {state}")
    if state:  # ya ha empezado la transferencia
        i = state.idx
        n_attempts = state.n_attempts
    else:
        write_to_file(job_executor.log_filenames_dict["download_stdout"],
                      "#" * 20 + " TRANSFER DATA FROM RESOURCE STEP " + "#" * 20)
        open(job_executor.log_filenames_dict["download_stderr"], "x")
        i = 0
        n_attempts = 0
        jc.pid = None
        jc.state_dict = dict(idx=i, n_attempts=n_attempts, state="download")

    # Files to transfer
    files = job_executor.get_download_files_list(jc)
    file_dict = files[i] if i < len(files) else {"file": "", "remote_name": "", "type": ""}

    if not job_executor.check():
        error_str = "Connection to the server has been lost"
        print(error_str)
        write_to_file(job_executor.log_filenames_dict["download_stderr"], error_str)
        write_to_universal_log_and_truncate(job_executor.log_filenames_dict["download_stdout"],
                                            job_executor.log_filenames_dict["download_stderr"],
                                            job_executor.log_filenames_dict["universal_log"])
        jc.error = error_str
        return "error", d2s(jc)
    elif i < len(files) and n_attempts >= MAX_ATTEMPTS:
        error_str = f"Transfer from resource error: File {file_dict['file']}"
        write_to_file(job_executor.log_filenames_dict["download_stderr"], error_str)
        write_to_universal_log_and_truncate(job_executor.log_filenames_dict["download_stdout"],
                                            job_executor.log_filenames_dict["download_stderr"],
                                            job_executor.log_filenames_dict["universal_log"])
        print(error_str)
        jc.error = error_str
        return "error", d2s(jc)
    if i == len(files):  # Transfer finished
        print("Transfer finished")
        write_to_file(job_executor.log_filenames_dict["download_stdout"], "Download finished successfully")
        write_to_universal_log_and_truncate(job_executor.log_filenames_dict["download_stdout"],
                                            job_executor.log_filenames_dict["download_stderr"],
                                            job_executor.log_filenames_dict["universal_log"])
        del jc.state_dict
        return d2s(jc)
    elif job_executor.step_status(jc) == "running":  # Transfer is being executed
        print("Transfer executing")
        return 1, job_context
    elif job_executor.step_status(jc) == "":
        jc.pid = None
        return None, d2s(jc)
    elif job_executor.exists(jc):  # File i has been transferred successfully
        print(f"File {file_dict['file']} transferred -> Moving to next")
        write_to_file(job_executor.log_filenames_dict["download_stdout"],
                      f"File {file_dict['file']} transferred -> Moving to next. Attempts: {n_attempts}")
        write_to_universal_log_and_truncate(job_executor.log_filenames_dict["download_stdout"],
                                            job_executor.log_filenames_dict["download_stderr"],
                                            job_executor.log_filenames_dict["universal_log"])
        jc.pid = None
        jc.state_dict = dict(idx=i + 1, n_attempts=0, state="download")
        return None, d2s(jc)
    else:  # Transfer file i
        print(f"Begin transfer {i + 1}: {file_dict['file']}. Attempt: {n_attempts + 1}")
        write_to_file(job_executor.log_filenames_dict["download_stdout"],
                      f"Begin transfer {i + 1}: {file_dict['file']}. Attempt: {n_attempts + 1}")
        pid = job_executor.download_file(jc)  # MAIN !!!
        jc.pid = pid
        jc.state_dict = dict(idx=i, n_attempts=n_attempts + 1, state="download")
        return None, d2s(jc)


@celery_app.task(name="store_result_in_backend")
@celery_wf(celery_app, wf1, "store_result_in_backend")
def wf1_store_result_in_backend(job_context: str):
    jc = s2d(job_context)
    job_executor = JobExecutorAtResourceFactory().get(jc)

    # TODO If "cancelling", remove files already uploaded to the backend
    #      Or if that is not possible, consider the cancellation not possible ("cancel cancellation"),
    #      and force a switch to "success".
    if not change_status_or_cancel_if_requested(jc,
                                                "store_result_in_backend",
                                                partial(kill_process, jc.get("pid"))):
        return "cancel", job_context

    state = jc.get("state_dict")

    print(f"Store result in backend state: {state}")
    if state:  # ya ha empezado la transferencia
        i = state.idx
        n_attempts = state.n_attempts
    else:
        write_to_file(job_executor.log_filenames_dict["store_stdout"],
                      "#" * 20 + " STORE RESULT IN BACKEND STEP " + "#" * 20)
        open(job_executor.log_filenames_dict["store_stderr"], "x")
        i = 0
        n_attempts = 0
        jc.pid = None
        jc.state_dict = dict(idx=i, n_attempts=n_attempts, state="store", check_url=None)

    # Files to transfer
    files = job_executor.get_download_files_list(jc)
    file_dict = files[i] if i < len(files) else {"file": "", "remote_name": "", "type": ""}
    status = job_executor.step_status(jc)
    if i < len(files) and n_attempts >= MAX_ATTEMPTS:
        error_str = f"Store result in backend error: File {file_dict['file']}"
        write_to_file(job_executor.log_filenames_dict["store_stderr"], error_str)
        write_to_universal_log_and_truncate(job_executor.log_filenames_dict["store_stdout"],
                                            job_executor.log_filenames_dict["store_stderr"],
                                            job_executor.log_filenames_dict["universal_log"])
        print(error_str)
        jc.error = error_str
        return "error", d2s(jc)
    elif i == len(files):  # Transfer finished
        log_file = os.path.basename(job_executor.log_filenames_dict["universal_log"])
        if files[-1]["file"] != log_file:
            write_to_file(job_executor.log_filenames_dict["store_stdout"],
                          "Store result in backend finished successfully")
            write_to_universal_log_and_truncate(job_executor.log_filenames_dict["store_stdout"],
                                                job_executor.log_filenames_dict["store_stderr"],
                                                job_executor.log_filenames_dict["universal_log"])
            jc.results.append(dict(remote_name="", file=log_file, content_type="text/plain", type="log"))
            return None, d2s(jc)

        print("Store result in backend finished")
        del jc.state_dict
        return d2s(jc)
    elif status == "running":  # Transfer is being executed
        print("Store result in backend executing")
        return 1, job_context
    elif status == "" or status == "ok":
        jc.pid = None
        return None, d2s(jc)
    elif "check_url" in jc.state_dict and check_file_is_stored_in_backend(jc.state_dict["check_url"]):  # File i has been transferred successfully
        print(f"File {file_dict['file']} stored -> Moving to next")
        write_to_file(job_executor.log_filenames_dict["store_stdout"],
                      f"File {file_dict['file']} stored -> Moving to next. Attempts: {n_attempts}")
        write_to_universal_log_and_truncate(job_executor.log_filenames_dict["store_stdout"],
                                            job_executor.log_filenames_dict["store_stderr"],
                                            job_executor.log_filenames_dict["universal_log"])
        jc.pid = None
        jc.state_dict = dict(idx=i + 1, n_attempts=0, state="store")
        api_logout()
        return None, d2s(jc)
    else:  # Store file i
        print(f"Beginning to store result in backend of file {file_dict['file']}. Attempt: {n_attempts + 1}")
        print(file_dict)
        write_to_file(job_executor.log_filenames_dict["store_stdout"],
                      f"Beginning to store result in backend of file {file_dict['file']}. Attempt: {n_attempts + 1}")
        endpoint = get_global_configuration_variable("ENDPOINT_URL")
        cookies_file_path = get_global_configuration_variable("COOKIES_FILE_PATH")
        filename = f'{file_dict["file"].split(".")[0]}.{file_dict["type"]}'
        local_path = os.path.join(job_executor.local_workspace, filename)
        print(file_dict)
        # MAIN !!!
        api_login()
        if "autoimport" in file_dict and file_dict["autoimport"]:
            file_dict["metadata"]["job_id"] = jc.job_id
            # instance_id = file_dict["metadata"].get("attributes", {}).get("instance_id")
            # port_id = file_dict["metadata"].get("attributes", {}).get("port_id")
            d = file_dict["object_type"]
            if "geo" in d:
                metadata = json.dumps(file_dict["metadata"].to_python()).replace('"', '\\"')
                curl_cmd = f"curl -s --cookie-jar {cookies_file_path} --cookie {cookies_file_path} " \
                           f"-F \"layer_file=@{local_path};type={file_dict['content_type']}\" " \
                           f"-F \"metadata={metadata};type=application/json\" " \
                           f"{endpoint}{app_api_base}/geo/layers/"
                check_url = f"{endpoint}{app_api_base}/geo/layers/job{jc.job_id}"
        else:
            curl_cmd = (f"curl -s --cookie-jar {cookies_file_path} --cookie {cookies_file_path} " +
                        f"-H \"Content-Type: {file_dict['content_type']}\" -XPUT --data-binary @\"{local_path}\" " +
                        f"\"{endpoint}{app_api_base}/files/jobs/{str(jc.job_id)}/{file_dict['file']}.content\"")
            check_url = f"{endpoint}{app_api_base}/files/jobs/{str(jc.job_id)}/{file_dict['file']}"
        cmd = (f"(nohup bash -c '{curl_cmd} ' >>{job_executor.log_filenames_dict['store_stdout']} " +
               f"</dev/null 2>>{job_executor.log_filenames_dict['store_stderr']} & echo $!; wait $!; " +
               f"echo $? >> {job_executor.local_workspace}/$!.exit_status)")
        print(cmd)
        popen_pipe = os.popen(cmd)
        pid = popen_pipe.readline().rstrip()
        print(f"PID: {pid}")
        jc.pid = pid
        jc.state_dict = dict(idx=i, n_attempts=n_attempts + 1, state="store", check_url=check_url)
        return None, d2s(jc)


@celery_app.task(name="cleanup")
@celery_wf(celery_app, wf1, "cleanup")
def wf1_cleanup_workspace(job_context: str):
    """
    Delete workspace at the remote resource

    :param job_context:
    :return:
    """
    jc = s2d(job_context)
    job_executor = JobExecutorAtResourceFactory().get(jc, create_local_workspace=False)

    # Different from the other tasks: let the task execute, and if the status is cancelling, return to
    # "cancel" instead of to default
    cancelling = not change_status_or_cancel_if_requested(jc, "cleanup", None)

    state = jc.get("state_dict")

    print(f"Cleanup state: {state}")

    result_files = jc.results
    print(job_executor.job_workspace_exists())

    print(local_workspace_exists(job_executor.local_workspace, result_files))

    if state:  # ya ha empezado el prepare
        n_attempts = state.n_attempts
    else:
        n_attempts = 0
        # Cleanup cannot have logs, because it is after storage into the backend
        jc.state_dict = dict(n_attempts=n_attempts)

    if not job_executor.check():
        error_str = "Connection to the server has been lost"
        write_to_file(job_executor.log_filenames_dict["cleanup_stderr"], error_str)
        print(error_str)
        jc.error = error_str
        return "error", d2s(jc)
    elif n_attempts >= MAX_ATTEMPTS:
        error_str = f"It was impossible to remove the working directory of Job {jc['job_id']}." + \
                    f"Maybe it could be due to some disk space or credentials issue."
        jc.error = error_str
        # write_to_file(job_executor.log_filenames_dict["cleanup_stderr"], error_str)
        print(error_str)
        return "error", d2s(jc)
    elif ((not job_executor.job_workspace_exists()) and
          (not local_workspace_exists(job_executor.local_workspace, result_files))):
        del jc.state_dict
        write_to_file(CELERY_LOG, f"cleanup:")
        if cancelling:
            return "cancel", d2s(jc)  # Jump to "cancel" task
        else:
            return d2s(jc)  # Jump to default task (should be "success")
    else:
        # MAIN !!!
        print("aqui")
        job_executor.remove_job_workspace()
        print("aqui2")
        remove_local_workspace(job_executor.local_workspace, result_files)
        jc.state_dict = dict(n_attempts=n_attempts + 1)
        return None, d2s(jc)


@celery_app.task(name="success")
@celery_wf(celery_app, wf1, "success")
def wf1_completed_succesfully(job_context: str):
    """
    Just mark the Job as "completed succesfully"

    :param job_context:
    :return:
    """
    jc = s2d(job_context)
    refresh_status(jc, "success")
    call_app_entity_status_callback(jc, "success")
    write_to_file(CELERY_LOG, "completed_successfully")
    write_to_file(CELERY_LOG, f"success:")
    return d2s(jc)


@celery_app.task(name="error")
@celery_wf(celery_app, wf1, "error")
def wf1_completed_error(job_context: str):
    """
    Mark the Job as "completed with error"

    :param job_context:
    :return:
    """
    jc = s2d(job_context)
    refresh_status(jc, "error")
    call_app_entity_status_callback(jc, "error")

    # TODO write_to_file(CELERY_LOG, f"error: {tmp['error']}")
    previous_state = jc.state_dict.state
    if previous_state == "store" or previous_state == "cleanup":
        return job_context

    job_executor = JobExecutorAtResourceFactory().get(jc)
    jc.results = clean_failed_results(jc.results, job_executor.local_workspace)
    del jc.state_dict  # needed to store to work

    # TODO ??????????
    return "wf1_store_result_in_backend", d2s(jc)


@celery_app.task(name="cancel")
@celery_wf(celery_app, wf1, "cancel")
def wf1_cancelled(job_context: str):
    """
    Mark the Job as "cancelled"

    :param job_context:
    :return:
    """
    jc = s2d(job_context)
    refresh_status(jc, "cancelled")
    call_app_entity_status_callback(jc, "cancelled")
    write_to_file(CELERY_LOG, f"cancelled")
    return job_context
