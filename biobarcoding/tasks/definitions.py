import json
import logging
import os
import re
import shutil
import signal
import subprocess
import traceback
from functools import partial
from json import JSONDecodeError

from celery.utils.log import get_task_logger
from dotted.collection import DottedDict

from .. import get_global_configuration_variable
from ..common import ROOT
from ..common.decorators import celery_wf
from ..jobs import JobExecutorAtResourceFactory
from ..rest import app_api_base
from . import celery_app

"""
To debug Celery tasks, create a Run/Debug configuration:
 * of type "Python"
 * Script path: /home/rnebot/anaconda3/bin/celery
 * Parameters-: -A rvc.tasks worker --pool=solo --loglevel=info
 * Python interpreter: <use the same environment where the Backend is executed
 * Optionally, create a Run/Debug configuration of type "Compound":
   - Add the previous Run/Debug configuration
   - Also, the Run/Debug configuration for the Backend 

To test:
- Run "app-backend" in the IDE
- Open three shells in the "app-backend" directory:
  - ./start_local_dev_services.sh
  - python3 biobarcoding/rest/main.py
  - celery -A biobarcoding.tasks.definitions flower [OPTIONAL: to see tasks, http://localhost:5555]
  - curl -i -XPOST http://localhost:5000/api/jobs/ --data-urlencode "{}" --> (should return immediately)
    - (to see messages generated by tasks of this workflow) tail -f /home/rnebot/Downloads/borrame/log.txt
  - curl -i -XPOST http://localhost:5000/api/jobs/ -H "Content-Type: application/json" -d @"/home/daniel/Documentos/GIT/app-backend/tests/request_transfer.json"
  - curl --cookie-jar app-cookies.txt --cookie app-cookies.txt -XPOST http://localhost:5000/api/jobs/ -H "Content-Type: application/json" -d @"/home/paula/Documentos/app-backend/tests/data_test/new_galaxy_request.json"

"""

logger = get_task_logger(__name__)

MAX_ATTEMPTS = 3
CELERY_LOG = ROOT + "/tests/data_test/celery_log.txt"
wf1 = {
    "prepare": {
        "": "export",
        "error": "error",
        "cancel": "cleanup"
    },
    "export": {
        "": "transfer_data",
        "cancel": "cleanup"
    },
    "transfer_data": {
        "": "submit",
        "cancel": "cleanup"
    },
    "submit": {
        "cancel": "cleanup",
        "": "wait_until_execution_starts"
    },
    "wait_until_execution_starts": {
        "": "wait_for_execution_end",
        "error": "error",
        "cancel": "cleanup"
    },
    "wait_for_execution_end": {
        "": "transfer_data_from",
        "error": "error",
        "cancel": "cleanup"
    },
    "transfer_data_from": {
        "": "store_result_in_backend",
        "cancel": "cancel"
    },
    "store_result_in_backend": {
        "": "cleanup",
        "cancel": "cancel"
    },
    "cleanup": {
        "": "success",
        "cancel": "cancel"
    },
    # "success"
    # "error"
    # "cancelled"
}


def put_json_at_backend_endpoint(path: str, json_str: str):
    endpoint = get_global_configuration_variable("ENDPOINT_URL")
    cookies_file_path = get_global_configuration_variable("COOKIES_FILE_PATH")
    url = f"{endpoint}{app_api_base}{path}"
    api_login()
    cmd = ["curl", "--cookie-jar", cookies_file_path, "--cookie", cookies_file_path, "-H",
           "Content-Type: application/json", "-XPUT", "--data-binary", json_str, url]
    proc = subprocess.run(cmd, capture_output=True, text=True)
    try:
        process_return_dict = json.loads(proc.stdout)
        return process_return_dict.get("content", {})
    except JSONDecodeError:
        traceback.print_exc()
        return {}


def refresh_status(d: DottedDict, status: str):
    job_id = d.job_id
    url = f"/jobs/{job_id}"
    status_request = json.dumps(dict(status=status))
    output = put_json_at_backend_endpoint(url, status_request)
    status_set = output.get("status", status)
    d.status = status_set
    return status_set


def change_status_or_cancel_if_requested(jc, job_status, cancel_task_function):
    """
    First it tries to change the "status" property of the Job (used to inform progress)

    If the status returned by the Backend is "cancelling", it returns False
    True is returned otherwise

    When cancelling:
     * call the "cancel_task_function" (if defined)
     * return False to inform tasks that they must cancel its current process and move to "cleanup"

    :param jc:
    :param job_status:
    :param cancel_task_function:
    :return:
    """
    status = refresh_status(jc, job_status)
    if status == "cancelling":
        if cancel_task_function:
            cancel_task_function()
        return False
    else:
        return True


def kill_process(pid):
    if pid:
        try:
            os.kill(int(pid), signal.SIGTERM)
        except Exception as e:
            logger.error(e)
            traceback.print_exc()


def call_app_entity_status_callback(jc: DottedDict, status: str):
    """
    "app entity" considered to be a separate thing from elaboration (job execution) of it
    Useful to provide higher level view of the status of this entity (without knowing about "jobs")

    :param jc:
    :param status:
    :return:
    """
    s = f"{status}_status"
    if "callbacks" in jc.process and "endpoint" in jc.process.callbacks and s in jc.process.callbacks:
        status_request = json.dumps(dict(status=status))
        output = put_json_at_backend_endpoint(jc.process.callbacks.endpoint, status_request)
        if output:
            status_set = output.get("status", status)


def can_execute_job(job_id):
    endpoint = get_global_configuration_variable("ENDPOINT_URL")
    cookies_file_path = get_global_configuration_variable("COOKIES_FILE_PATH")
    url = f"{endpoint}{app_api_base}/jobs/{job_id}"
    api_login()
    cmd = ["curl", "--cookie", cookies_file_path, f"{url}"]
    proc = subprocess.run(cmd, capture_output=True, text=True)
    _ = proc.stdout
    api_logout()
    try:
        d = json.loads(_)
    except JSONDecodeError as e:
        logger.error(e)
        return False
    if d.get("content"):
        _ = d["content"]
        executability = _.get("executability",
                              "resource_ok_can_execute" if _["status"] in ("cancelled", "cancelling") else "resource_ko")
        return executability == "resource_ok_can_execute"
    else:
        if d.get("issues"):
            if d["issues"][0]["type"] == "ERROR" and "not found" in d["issues"][0]["message"]:
                return "job_does_not_exist"  # Not a boolean
        return False


def write_to_file(filename, s):
    try:
        with open(filename, "a+") as f:
            f.write(s + "\r\n")
    except:
        logger.debug(f"Warning: could not write '{s}' to file '{filename}'")


celery_user = "celery_user"


def api_login():
    endpoint = get_global_configuration_variable("ENDPOINT_URL")
    cookies_file_path = get_global_configuration_variable("COOKIES_FILE_PATH")
    url = f"{endpoint}{app_api_base}/authn?user={celery_user}"
    cmd = ["curl", "--cookie", cookies_file_path, "--cookie-jar", cookies_file_path, "-X", "PUT", url]
    subprocess.run(cmd)


def api_logout():
    endpoint = get_global_configuration_variable("ENDPOINT_URL")
    # cookies_file_path = get_global_configuration_variable("COOKIES_FILE_PATH")
    # url = f"{endpoint}{app_api_base}/authn?user={celery_user}"
    # cmd = ["curl", "--cookie", cookies_file_path, "--cookie-jar", cookies_file_path, "-X", "DELETE", url]
    # subprocess.run(cmd)


def check_file_is_stored_in_backend(check_url):
    if not check_url:
        return False
    cookies_file_path = get_global_configuration_variable("COOKIES_FILE_PATH")
    api_login()
    cmd = ["curl", "--cookie-jar", cookies_file_path, "--cookie",
           cookies_file_path, f"{check_url}"]
    proc = subprocess.run(cmd, capture_output=True, text=True)
    _ = proc.stdout
    api_logout()
    try:
        process_return_dict = json.loads(_)
    except JSONDecodeError as e:
        logger.error(e)
        return False
    if process_return_dict.get("content"):
        return process_return_dict["content"].get("size") != 0
    else:
        return False


def clean_failed_results(result_files, local_workspace):
    clean_results = []
    for f in result_files:
        if os.path.exists(os.path.join(local_workspace, f["file"])):
            clean_results.append(f)
    return clean_results


def remove_local_workspace(local_workspace, result_files=None):
    shutil.rmtree(local_workspace)

    # result_filenames = [os.path.basename(f["file"]) for f in result_files]
    # for f in os.listdir(local_workspace):
    #     if f not in result_filenames:
    #         os._(os.path.join(local_workspace, f))


def local_workspace_exists(local_workspace, result_files=None):
    _ = os.path.exists(local_workspace)
    return _
    # cleaned = True
    # result_filenames = [os.path.basename(f["file"]) for f in result_files]
    # local_workspace_files = os.listdir(local_workspace)
    # if len(result_filenames) == len(local_workspace_files):
    #     for f in local_workspace_files:
    #         if f not in result_filenames:
    #             cleaned = False
    # else:
    #     cleaned = False
    # return cleaned


def write_to_universal_log_and_truncate(step_stdout, step_stderr, universal_log):
    stdout_file = open(step_stdout, 'r+')
    stderr_file = open(step_stderr, 'r+')
    stdout = stdout_file.read()
    stderr = stderr_file.read()
    stdout_file.truncate(0)
    stderr_file.truncate(0)
    stdout_file.close()
    stderr_file.close()

    step_log = f"\n{stdout}\nAPP_STDERR\n{stderr}APP_STDERR\n"
    with open(universal_log, "a+") as universal_log_file:
        universal_log_file.write(step_log)


def generate_export_cmd(file_dict: dict, tmp_path: str, job_executor):
    endpoint: str = get_global_configuration_variable("ENDPOINT_URL")
    cookies_file_path: str = get_global_configuration_variable("COOKIES_FILE_PATH")
    extension: str = file_dict['type']
    object_type: dict = file_dict['object_type']
    selection = file_dict['selection']
    queryParams = file_dict['queryParams']
    with_filter = False
    if type(selection) == dict:  # Get with filter
        selection_json: str = json.dumps(selection)
        with_filter = True
    elif type(selection) == DottedDict:  # Get with filter
        selection_json: str = d2s(selection)
        with_filter = True
    url = ""
    if "bos" in object_type.keys() and object_type['bos'] == 'sequences':
        url = f"{endpoint}{app_api_base}/bos/{object_type['bos']}.{extension}{queryParams}"
    elif "bos" in object_type.keys() and object_type['bos'] in ['alignments', 'phylotrees']:
        url = f"{endpoint}{app_api_base}/bos/{object_type['bos']}/{selection}.{extension}{queryParams}"
    elif "geo" in object_type.keys():
        if object_type['geo'] == "layers":
            url = f"{endpoint}{app_api_base}/geo/{object_type['geo']}/{selection}.{extension}{queryParams}"
    elif "files" in object_type.keys():
        url = f"{endpoint}{app_api_base}/files/{object_type['files']}.content"

    if with_filter:
        curl = (f"curl --cookie-jar {cookies_file_path} --cookie {cookies_file_path} -X GET -d \'{selection_json}\' " +
                f"-H \'Content-Type:application/json\' {url} -o \'{tmp_path}\'")
        return (f"(nohup bash -c &quot;{curl}&quot; >>{job_executor.log_filenames_dict['export_stdout']} " +
                f"</dev/null 2>>{job_executor.log_filenames_dict['export_stderr']} & echo $!; wait $!; " +
                f"echo $? >> {job_executor.local_workspace}/$!.exit_status)")
    else:
        curl = f"curl --cookie {cookies_file_path} -X GET {url} -o \'{tmp_path}\'"
        return (f"(nohup bash -c \"{curl}\" >>{job_executor.log_filenames_dict['export_stdout']} " +
                f"</dev/null 2>>{job_executor.log_filenames_dict['export_stderr']} & echo $!; wait $!; " +
                f"echo $? >> {job_executor.local_workspace}/$!.exit_status)")


# TODO: Hay que prepararlo para las colecciones y los ficheros que suba el usuario de manera
#  que se puedan concatenar si se refieren al mismo fichero.
#  Mirar: https://stackoverflow.com/questions/40359012/how-to-append-a-file-with-the-existing-one-using-curl

def export(file_dict, job_executor) -> object:
    """
    Export file to the local workspace (which depends on "job_executor")

    @param file_dict: Dictionary of the file to be exported
    @param job_executor: Needed to know local_workspace and log names
    @return: pid: PID of the executed script process
    """
    api_login()  # Logout is executed after successful export
    tmp_path = os.path.join(job_executor.local_workspace, file_dict["remote_name"])
    cmd = generate_export_cmd(file_dict, tmp_path, job_executor)
    logger.debug(cmd)
    popen_pipe = os.popen(cmd)
    pid = popen_pipe.readline().rstrip()
    logger.debug(f"PID: {pid}")
    return pid


def import_(file_dict, job_executor, jc):
    endpoint = get_global_configuration_variable("ENDPOINT_URL")
    cookies_file_path = get_global_configuration_variable("COOKIES_FILE_PATH")
    local_path = os.path.join(job_executor.local_workspace, file_dict["file"])
    logger.debug(file_dict)
    api_login()
    if "autoimport" in file_dict and file_dict["autoimport"]:
        file_dict["metadata"]["job_id"] = jc.job_id
        # instance_id = file_dict["metadata"].get("attributes", {}).get("instance_id")
        # port_id = file_dict["metadata"].get("attributes", {}).get("port_id")
        d = file_dict["object_type"]
        if "geo" in d:
            metadata = json.dumps(file_dict["metadata"].to_python()).replace('"', '\\"')
            curl_cmd = f"curl -s --cookie-jar {cookies_file_path} --cookie {cookies_file_path} " \
                       f"-F \"layer_file=@{local_path};type={file_dict['content_type']}\" " \
                       f"-F \"metadata={metadata};type=application/json\" " \
                       f"{endpoint}{app_api_base}/geo/layers/"
            check_url = f"{endpoint}{app_api_base}/geo/layers/job{jc.job_id}"
    else:
        curl_cmd = (f"curl -s --cookie-jar {cookies_file_path} --cookie {cookies_file_path} " +
                    f"-H \"Content-Type: {file_dict['content_type']}\" -XPUT --data-binary @\"{local_path}\" " +
                    f"\"{endpoint}{app_api_base}/files/jobs/{str(jc.job_id)}/{file_dict['file']}.content\"")
        check_url = f"{endpoint}{app_api_base}/files/jobs/{str(jc.job_id)}/{file_dict['file']}"
    cmd = (f"(nohup bash -c '{curl_cmd} ' >>{job_executor.log_filenames_dict['store_stdout']} " +
           f"</dev/null 2>>{job_executor.log_filenames_dict['store_stderr']} & echo $!; wait $!; " +
           f"echo $? >> {job_executor.local_workspace}/$!.exit_status)")
    logger.debug(cmd)
    popen_pipe = os.popen(cmd)
    pid = popen_pipe.readline().rstrip()
    logger.debug(f"PID: {pid}")
    return pid, dict(check_url=check_url)


def is_file_exported(input_file):
    if os.path.exists(input_file):  # and check that it is not an error file:
        try:
            with open(input_file, "r") as file:
                file_content = file.read()
                file.close()
            if not re.search(r'\b<!DOCTYPE HTML PUBLIC\b', file_content):
                return True
            else:
                logger.warning(f"{input_file} is a html file")
                return False
        except:
            return True  # If the search cannot be performed, it is a binary file, OK
    else:
        logger.warning(f"{input_file} does not exists")
        return False


def s2d(s: str) -> DottedDict:
    return DottedDict(json.loads(s))


def d2s(d: DottedDict) -> str:
    return json.dumps(d.to_python())


def transfer_task(task_name,
                  logs_prefix,
                  jc,
                  job_executor,
                  action_function,
                  check_action_function,
                  after_action_function,
                  files_function,
                  log_msg):
    """
    Valid for the four
    :param task_name:
    :param job_context:
    :param job_executor:
    :param action_function:
    :param log_msg:
    :return:
    """
    if not change_status_or_cancel_if_requested(jc,
                                                task_name,
                                                partial(kill_process, jc.get("pid"))):
        return "cancel", d2s(jc)

    state = jc.get("state_dict")

    if state:  # transfer already started
        i = state.idx
        n_attempts = state.n_attempts
    else:
        write_to_file(job_executor.log_filenames_dict[f"{logs_prefix}_stdout"],
                      "#" * 20 + log_msg + "#" * 20)
        open(job_executor.log_filenames_dict[f"{logs_prefix}_stderr"], "x")
        i = 0
        n_attempts = 0
        jc.pid = None
        jc.state_dict = dict(idx=i, n_attempts=n_attempts, state=task_name)

    # Files to process
    files = files_function(jc, job_executor)
    file_dict = files[i] if i < len(files) else dict(file="", remote_name="", type="")
    logger.debug(file_dict)

    if not job_executor.check():
        error_str = "Connection to the server has been lost"
        logger.error(error_str)
        write_to_file(job_executor.log_filenames_dict[f"{logs_prefix}_stderr"], error_str)
        write_to_universal_log_and_truncate(job_executor.log_filenames_dict[f"{logs_prefix}_stdout"],
                                            job_executor.log_filenames_dict[f"{logs_prefix}_stderr"],
                                            job_executor.log_filenames_dict["universal_log"])
        jc.error = error_str
        return "error", d2s(jc)
    elif i < len(files) and n_attempts >= MAX_ATTEMPTS:
        # error_str = f"Transfer of file {os.path.basename(file_dict['file'])} to resource failed."
        error_str = f"'{task_name}' error: File {i + 1} {file_dict['remote_name']}"
        write_to_file(job_executor.log_filenames_dict[f"{logs_prefix}_stderr"], error_str)
        write_to_universal_log_and_truncate(job_executor.log_filenames_dict[f"{logs_prefix}_stdout"],
                                            job_executor.log_filenames_dict[f"{logs_prefix}_stderr"],
                                            job_executor.log_filenames_dict["universal_log"])
        jc.error = error_str
        return "error", d2s(jc)
    elif i == len(files):  # Task finished
        logger.debug(f"{task_name} finished")
        write_to_file(job_executor.log_filenames_dict[f"{logs_prefix}_stdout"],
                      f"{task_name} finished successfully")
        write_to_universal_log_and_truncate(job_executor.log_filenames_dict[f"{logs_prefix}_stdout"],
                                            job_executor.log_filenames_dict[f"{logs_prefix}_stderr"],
                                            job_executor.log_filenames_dict["universal_log"])
        del jc.state_dict
        # TODO Only last task (store results in backend)
        # log_file = os.path.basename(job_executor.log_filenames_dict["universal_log"])
        # jc.results.append(dict(remote_name="", file=log_file, content_type="text/plain", type="log"))
        return d2s(jc)
    elif job_executor.step_status(jc) == "running":  # TASK is being executed
        logger.debug(f"{task_name} executing")
        return 1, d2s(jc)
    elif job_executor.step_status(jc) == "":  # ERROR job_executor.step_status(jc) == "ok" for "store_result_in_backend"
        logger.debug(f"{task_name} error: File {i + 1}")
        jc.pid = None
        return None, d2s(jc)
    elif check_action_function(jc, job_executor):
        logger.debug(f"File {file_dict['remote_name']} {task_name}ed -> Moving to next. Attempt: {n_attempts}")
        write_to_file(job_executor.log_filenames_dict[f"{logs_prefix}_stdout"],
                      f"File {file_dict['remote_name']} {logs_prefix}ed -> Moving to next. Attempt: {n_attempts + 1}")
        write_to_universal_log_and_truncate(job_executor.log_filenames_dict[f"{logs_prefix}_stdout"],
                                            job_executor.log_filenames_dict[f"{logs_prefix}_stderr"],
                                            job_executor.log_filenames_dict["universal_log"])

        if after_action_function:
            after_action_function(jc, job_executor, file_dict)

        jc.pid = None
        jc.state_dict = dict(idx=i + 1, n_attempts=0, state=task_name)
        # TODO api_logout()
        return None, d2s(jc)
    else:  # TRANSFER file i
        logger.debug(f"Begin {task_name} {i + 1}: {file_dict['remote_name']}. Attempt: {n_attempts + 1}")
        write_to_file(job_executor.log_filenames_dict[f"{logs_prefix}_stdout"],
                      f"Begin {task_name} {i + 1}: {file_dict['remote_name']}. Attempt: {n_attempts + 1}")
        write_to_universal_log_and_truncate(job_executor.log_filenames_dict[f"{logs_prefix}_stdout"],
                                            job_executor.log_filenames_dict[f"{logs_prefix}_stderr"],
                                            job_executor.log_filenames_dict["universal_log"])

        pid, _ = action_function(file_dict, job_executor, jc)  # MAIN!!!

        jc.pid = pid
        jc.state_dict = dict(idx=i, n_attempts=n_attempts + 1, state=task_name)
        jc.state_dict.update(_)
        return None, d2s(jc)


# ----------------------------------------------------------------------------------------------------------------------
# THE TASKS
# ----------------------------------------------------------------------------------------------------------------------
ack_late_idempotent_tasks = True


@celery_app.task(name="prepare", ack_late=ack_late_idempotent_tasks)
@celery_wf(celery_app, wf1, "prepare")
def wf1_prepare_workspace(job_context):
    """
    Prepare workspace for execution of a Job
    :param job_context:
    :return:
    """
    jc = s2d(job_context)

    # Before proceeding with this and next tasks, check if execution must be contained,
    # wait 5 seconds if that is the case and return here
    if jc.status == "created":
        res = can_execute_job(jc.job_id)
        if res == "job_does_not_exist":
            return "error", d2s(jc)
        elif not res:
            return 5, job_context

    job_executor = JobExecutorAtResourceFactory().get(jc)
    if not change_status_or_cancel_if_requested(jc, "preparing_workspace", None):
        return "cancel", job_context

    state = jc.get("state_dict")

    logging.debug(f"Prepare state: {state}")

    if state:  # ya ha empezado el prepare
        n_attempts = state.n_attempts
    else:
        n_attempts = 0
        write_to_file(job_executor.log_filenames_dict["prepare_stdout"],
                      "#" * 25 + " PREPARE WORKSPACE STEP " + "#" * 25)
        # TODO Why this open? Exclusive creation but then it is not closed
        open(job_executor.log_filenames_dict["prepare_stderr"], "x")
        jc.state_dict = dict(n_attempts=n_attempts, state="prepare")

    if not job_executor.check():  # No connection to the compute resource
        error_str = "Connection to the server has been lost"
        jc.error = error_str
        write_to_file(job_executor.log_filenames_dict["prepare_stderr"], error_str)
        write_to_universal_log_and_truncate(job_executor.log_filenames_dict["prepare_stdout"],
                                            job_executor.log_filenames_dict["prepare_stderr"],
                                            job_executor.log_filenames_dict["universal_log"])
        return "error", d2s(jc)
    elif n_attempts >= MAX_ATTEMPTS:  # Maximum number of
        jc.error = f"It was impossible to prepare the working directory of Job {jc.job_id}." + \
                   f"Maybe it could be due to some disk space or credentials issue."
        write_to_file(job_executor.log_filenames_dict["prepare_stderr"], jc.error)
        write_to_universal_log_and_truncate(job_executor.log_filenames_dict["prepare_stdout"],
                                            job_executor.log_filenames_dict["prepare_stderr"],
                                            job_executor.log_filenames_dict["universal_log"])
        return "error", d2s(jc)
    elif job_executor.job_workspace_exists() or job_executor.job_workspace_exists() is None:
        logger.info("Job workspace created")
        # None when the job is executed in localhost
        write_to_file(job_executor.log_filenames_dict["prepare_stdout"], f"Job {jc.job_id} workspace prepared")
        write_to_universal_log_and_truncate(job_executor.log_filenames_dict["prepare_stdout"],
                                            job_executor.log_filenames_dict["prepare_stderr"],
                                            job_executor.log_filenames_dict["universal_log"])
        del jc.state_dict
        return d2s(jc)
    else:
        write_to_file(job_executor.log_filenames_dict["prepare_stdout"],
                      f"Preparing Job {jc.job_id} workspace: Attempt: {n_attempts + 1}")
        jc.state_dict = dict(n_attempts=n_attempts + 1, state="prepare")
        # NOTE: Local workspace is created implicitly by "JobExecutorAtResourceFactory().get(jc)"
        job_executor.create_job_workspace()
        return None, d2s(jc)


@celery_app.task(name="export", ack_late=ack_late_idempotent_tasks)
@celery_wf(celery_app, wf1, "export")
def wf1_export_to_supported_file_formats(job_context: str):
    """
    Prepare input files by exporting data using RESTful services

    :param job_context:
    :return:
    """
    jc = s2d(job_context)
    job_executor = JobExecutorAtResourceFactory().get(jc)

    def after_export(jc, job_executor, file_dict):
        i = jc.state_dict.idx
        jc.process.inputs.data[i]['file'] = os.path.join(job_executor.local_workspace, file_dict["remote_name"]) # TODO: check if this is correct
        del jc.process.inputs.data[i]['selection']

    ret_tuple = transfer_task(task_name="export",
                              logs_prefix="export",
                              jc=jc,
                              job_executor=job_executor,
                              action_function=lambda file_dict, je, jc: (export(file_dict, je), {}),
                              check_action_function=lambda jc, je: is_file_exported(os.path.join(je.local_workspace, jc.process.inputs.data[jc.state_dict.idx]["remote_name"])),
                              after_action_function=after_export,
                              files_function=lambda job_context, job_executor: job_context.process.inputs.data,
                              log_msg=" EXPORT TO SUPPORTED FILE FORMATS STEP ")
    logger.debug(f"RET: {ret_tuple}")
    return ret_tuple


@celery_app.task(name="transfer_data", ack_late=ack_late_idempotent_tasks)
@celery_wf(celery_app, wf1, "transfer_data")
def wf1_transfer_data_to_resource(job_context: str) -> object:
    """
    Transfer data to the compute resource
    :param job_context:
    :return:
    """
    jc = s2d(job_context)
    job_executor = JobExecutorAtResourceFactory().get(jc)

    def check_file_exists(jc, job_executor):
        _ = jc.state_dict.state
        jc.state_dict.state = "upload"
        res = job_executor.exists(jc)
        jc.state_dict.state = _
        return res

    def get_files_to_upload(jc, job_executor):
        _ = [i for i in job_executor.get_upload_files_list(jc)
             if not isinstance(i, str) or (isinstance(i, str) and not i.startswith("geoprocess"))]
        return _

    ret_tuple = transfer_task(task_name="transfer_data_to_resource",
                              logs_prefix="upload",
                              jc=jc,
                              job_executor=job_executor,
                              action_function=lambda file_dict, je, jc: (je.upload_file(jc), {}),
                              check_action_function=check_file_exists,
                              after_action_function=None,
                              files_function=get_files_to_upload,
                              log_msg=" TRANSFER DATA TO SOURCE STEP ")
    return ret_tuple


@celery_app.task(name="submit", ack_late=False)  # ack_late=False - NOT IDEMPOTENT
@celery_wf(celery_app, wf1, "submit")
def wf1_submit(job_context: str):
    """
    Submit job to compute resource
    :param job_context:
    :return:
    """
    jc = s2d(job_context)
    job_executor = JobExecutorAtResourceFactory().get(jc)

    if not change_status_or_cancel_if_requested(jc,
                                                "submit",
                                                partial(job_executor.cancel_job, jc.get("pid"))):
        return "cancel", job_context

    write_to_file(job_executor.log_filenames_dict["submit_stdout"], "#" * 25 + " SUBMIT STEP " + "#" * 25)
    open(job_executor.log_filenames_dict["submit_stderr"], "x")

    jc.pid = job_executor.submit(jc["process"])  # MAIN !!!

    jc.state_dict = dict(state="submit", substep="submit")
    write_to_file(CELERY_LOG, f"Submit job with PID: {jc.pid}")
    write_to_file(job_executor.log_filenames_dict["submit_stdout"],
                  f"Submit job with PID: {jc.pid}")
    return d2s(jc)


@celery_app.task(name="wait_until_execution_starts", ack_late=ack_late_idempotent_tasks)
@celery_wf(celery_app, wf1, "wait_until_execution_starts")
def wf1_wait_until_execution_starts(job_context: str):
    """
    Wait for the job to start executing at the
    :param job_context:
    :return:
    """
    jc = s2d(job_context)
    job_executor = JobExecutorAtResourceFactory().get(jc)

    if not change_status_or_cancel_if_requested(jc,
                                                "wait_until_execution_starts",
                                                partial(job_executor.cancel_job, jc.get("pid"))):
        return "cancel", job_context

    jc.state_dict = dict(state="submit", substep="wait_until_execution_starts")
    if not job_executor.check():
        error_str = "Connection to the server has been lost"
        write_to_file(job_executor.log_filenames_dict["submit_stderr"], error_str)
        write_to_universal_log_and_truncate(job_executor.log_filenames_dict["submit_stdout"],
                                            job_executor.log_filenames_dict["submit_stderr"],
                                            job_executor.log_filenames_dict["universal_log"])
        logger.error(error_str)
        jc.error = error_str
        return "error", d2s(jc)
    status = job_executor.step_status(jc)
    write_to_file(CELERY_LOG, f"wait_until_execution_starts: status: {status}")
    # TODO: el step_status debería de sacar outputs uniformes. Se podría escribir ese
    # status en el log en el job_executor?
    if isinstance(status, dict) or status == "":
        if status != "":
            jc.process.error = status
            error_str = f"The process failed to start with status: {status}."
        else:
            error_str = "The process failed to start."
        logger.error(error_str)
        write_to_file(job_executor.log_filenames_dict["submit_stderr"], json.dumps(error_str))
        write_to_universal_log_and_truncate(job_executor.log_filenames_dict["submit_stdout"],
                                            job_executor.log_filenames_dict["submit_stderr"],
                                            job_executor.log_filenames_dict["universal_log"])
        jc.error = error_str
        return 'error', d2s(jc)
    elif status == 'running' or status == 'ok':
        return job_context
    else:
        return 3, job_context


@celery_app.task(name="wait_for_execution_end", ack_late=ack_late_idempotent_tasks)
@celery_wf(celery_app, wf1, "wait_for_execution_end")
def wf1_wait_for_execution_end(job_context: str):
    """
    Wait for the job to finish execution, knowing it is running
    When finished, it can end successfully or with an error.

    :param job_context:
    :return:
    """
    jc = s2d(job_context)
    job_executor = JobExecutorAtResourceFactory().get(jc)

    if not change_status_or_cancel_if_requested(jc,
                                                "wait_for_execution_end",
                                                partial(job_executor.cancel_job, jc.get("pid"))):
        return "cancel", job_context

    jc.state_dict = dict(state="submit", substep="wait_for_execution_end")
    status = job_executor.step_status(jc)
    write_to_file(CELERY_LOG, f"wait_for_execution_end: status: {status}")
    if not job_executor.check():
        error_str = "Connection to the server has been lost"
        logger.error(error_str)
        write_to_file(job_executor.log_filenames_dict["submit_stderr"], error_str)
        write_to_universal_log_and_truncate(job_executor.log_filenames_dict["submit_stdout"],
                                            job_executor.log_filenames_dict["submit_stderr"],
                                            job_executor.log_filenames_dict["universal_log"])
        jc.error = error_str
        return "error", d2s(jc)
    elif isinstance(status, dict):
        jc.process.error = status
        write_to_file(job_executor.log_filenames_dict["submit_stderr"], json.dumps(status))
        return 'error', d2s(jc)
    elif status == 'ok':
        del jc.state_dict
        write_to_file(job_executor.log_filenames_dict["submit_stdout"],
                      "Job execution finished successfully.")
        write_to_universal_log_and_truncate(job_executor.log_filenames_dict["submit_stdout"],
                                            job_executor.log_filenames_dict["submit_stderr"],
                                            job_executor.log_filenames_dict["universal_log"])
        return d2s(jc)
    elif status == "":
        # TODO job_executor.write_submit_logs()
        write_to_file(job_executor.log_filenames_dict["submit_stdout"],
                      "Job execution finished in error.")
        write_to_universal_log_and_truncate(job_executor.log_filenames_dict["submit_stdout"],
                                            job_executor.log_filenames_dict["submit_stderr"],
                                            job_executor.log_filenames_dict["universal_log"])
        return 'error', job_context
    else:
        return 3, job_context


@celery_app.task(name="transfer_data_from", ack_late=ack_late_idempotent_tasks)
@celery_wf(celery_app, wf1, "transfer_data_from")
def wf1_transfer_data_from_resource(job_context: str):
    """
    Once the computation ends, transfer results from the resource to local
    :param job_context:
    :return:
    """
    jc = s2d(job_context)
    job_executor = JobExecutorAtResourceFactory().get(jc)

    def check_file_exists(jc, job_executor):
        _ = jc.state_dict.state
        jc.state_dict.state = "download"
        res = job_executor.exists(jc)
        jc.state_dict.state = _
        return res

    ret_tuple = transfer_task(task_name="transfer_data_from_resource",
                              logs_prefix="download",
                              jc=jc,
                              job_executor=job_executor,
                              action_function=lambda file_dict, je, jc: (je.download_file(jc), {}),
                              check_action_function=check_file_exists,
                              after_action_function=None,
                              files_function=lambda jc, job_executor: job_executor.get_download_files_list(jc),
                              log_msg=" TRANSFER DATA FROM RESOURCE STEP ")
    return ret_tuple


@celery_app.task(name="store_result_in_backend", ack_late=ack_late_idempotent_tasks)
@celery_wf(celery_app, wf1, "store_result_in_backend")
def wf1_store_result_in_backend(job_context: str):
    jc = s2d(job_context)
    job_executor = JobExecutorAtResourceFactory().get(jc)
    ret_tuple = transfer_task(task_name="store_result_in_backend",
                              logs_prefix="store",
                              jc=jc,
                              job_executor=job_executor,
                              action_function=lambda file_dict, je, jc: import_(file_dict, je, jc),
                              check_action_function=lambda jc, je: "check_url" in jc.state_dict and check_file_is_stored_in_backend(jc.state_dict["check_url"]),
                              after_action_function=None,
                              files_function=lambda jc, job_executor: job_executor.get_download_files_list(jc),
                              log_msg=" STORE RESULT IN BACKEND STEP ")
    return ret_tuple


@celery_app.task(name="cleanup", ack_late=ack_late_idempotent_tasks)
@celery_wf(celery_app, wf1, "cleanup")
def wf1_cleanup_workspace(job_context: str):
    """
    Delete workspace at the remote resource

    :param job_context:
    :return:
    """
    logger.debug("cleanup 1 ----------")
    jc = s2d(job_context)
    job_executor = JobExecutorAtResourceFactory().get(jc, create_local_workspace=False)

    # Different from the other tasks: let the task execute, and if the status is cancelling, return to
    # "cancel" instead of to default
    cancelling = not change_status_or_cancel_if_requested(jc, "cleanup", None)

    state = jc.get("state_dict")

    logger.debug(f"Cleanup state: {state}")
    result_files = jc.results

    if state:  # ya ha empezado el prepare
        n_attempts = state.n_attempts
    else:
        n_attempts = 0
        # Cleanup cannot have logs, because it is after storage into the backend
        jc.state_dict = dict(n_attempts=n_attempts)

    if not job_executor.check():
        error_str = "Connection to the server has been lost"
        write_to_file(job_executor.log_filenames_dict["cleanup_stderr"], error_str)
        logger.error(error_str)
        jc.error = error_str
        return "error", d2s(jc)
    elif n_attempts >= MAX_ATTEMPTS:
        error_str = f"It was impossible to remove the working directory of Job {jc['job_id']}." + \
                    f"Maybe it could be due to some disk space or credentials issue."
        jc.error = error_str
        # write_to_file(job_executor.log_filenames_dict["cleanup_stderr"], error_str)
        logger.error(error_str)
        return "error", d2s(jc)
    elif ((not job_executor.job_workspace_exists()) and
          (not local_workspace_exists(job_executor.local_workspace, result_files))):
        del jc.state_dict
        write_to_file(CELERY_LOG, f"cleanup:")
        if cancelling:
            return "cancel", d2s(jc)  # Jump to "cancel" task
        else:
            return d2s(jc)  # Jump to default task (should be "success")
    else:
        # MAIN !!!
        try:
            job_executor.remove_job_workspace()
        except:
            traceback.print_exc()
        try:
            remove_local_workspace(job_executor.local_workspace, result_files)
        except:
            traceback.print_exc()
        jc.state_dict = dict(n_attempts=n_attempts + 1)
        return None, d2s(jc)


@celery_app.task(name="success", ack_late=ack_late_idempotent_tasks)
@celery_wf(celery_app, wf1, "success")
def wf1_completed_succesfully(job_context: str):
    """
    Just mark the Job as "completed succesfully"

    :param job_context:
    :return:
    """
    jc = s2d(job_context)
    refresh_status(jc, "success")
    call_app_entity_status_callback(jc, "success")
    write_to_file(CELERY_LOG, "completed_successfully")
    write_to_file(CELERY_LOG, f"success:")
    return d2s(jc)


@celery_app.task(name="error", ack_late=ack_late_idempotent_tasks)
@celery_wf(celery_app, wf1, "error")
def wf1_completed_error(job_context: str):
    """
    Mark the Job as "completed with error"

    :param job_context:
    :return:
    """
    jc = s2d(job_context)
    refresh_status(jc, "error")
    call_app_entity_status_callback(jc, "error")

    # TODO write_to_file(CELERY_LOG, f"error: {tmp['error']}")
    previous_state = jc.state_dict.state
    if previous_state == "store" or previous_state == "cleanup":
        return job_context

    job_executor = JobExecutorAtResourceFactory().get(jc)
    jc.results = clean_failed_results(jc.results, job_executor.local_workspace)
    del jc.state_dict  # needed to store to work

    # TODO ??????????
    return "wf1_store_result_in_backend", d2s(jc)


@celery_app.task(name="cancel", ack_late=ack_late_idempotent_tasks)
@celery_wf(celery_app, wf1, "cancel")
def wf1_cancelled(job_context: str):
    """
    Mark the Job as "cancelled"

    :param job_context:
    :return:
    """
    jc = s2d(job_context)
    refresh_status(jc, "cancelled")
    call_app_entity_status_callback(jc, "cancelled")
    write_to_file(CELERY_LOG, f"cancelled")
    return job_context
